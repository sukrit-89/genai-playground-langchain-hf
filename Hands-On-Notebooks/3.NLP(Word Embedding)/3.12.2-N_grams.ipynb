{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b02263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "text = pd.read_csv(r'D:\\Genai-lc-hf\\Datasets\\spam.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dafba5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5169, 2)\n",
      "\n",
      "First few rows:\n",
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "#cleaning and shapping\n",
    "text = text[['v1', 'v2']]\n",
    "text.columns = ['label', 'message']\n",
    "text.drop_duplicates(inplace=True)\n",
    "text.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Dataset shape:\", text.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fd77c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\`\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##data cleaning and preprocessing\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b01ac964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLEANING AND STEMMING WITHOUT STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "corpus=[]\n",
    "for i in range(0,len(text)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',text['message'][i]) #i am substituing the special characters in the message section\n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[ps.stem(word)for word in review if not word in stopwords.words('english')]\n",
    "    \n",
    "    review=' '.join(review)\n",
    "    \n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39ceb5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(max_features=100,binary=True)\n",
    "## here i am taking 2500 that has maximum number of occurance\n",
    "#also enabled binary BOW\n",
    "x=cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67955b57",
   "metadata": {},
   "source": [
    "This above are the BOW mdoel and these are the top 100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c744590c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': np.int64(23),\n",
       " 'great': np.int64(26),\n",
       " 'got': np.int64(25),\n",
       " 'wat': np.int64(92),\n",
       " 'ok': np.int64(58),\n",
       " 'free': np.int64(19),\n",
       " 'text': np.int64(79),\n",
       " 'txt': np.int64(87),\n",
       " 'say': np.int64(69),\n",
       " 'alreadi': np.int64(0),\n",
       " 'think': np.int64(82),\n",
       " 'hey': np.int64(29),\n",
       " 'week': np.int64(94),\n",
       " 'back': np.int64(5),\n",
       " 'like': np.int64(39),\n",
       " 'still': np.int64(74),\n",
       " 'send': np.int64(71),\n",
       " 'even': np.int64(16),\n",
       " 'friend': np.int64(20),\n",
       " 'prize': np.int64(64),\n",
       " 'claim': np.int64(9),\n",
       " 'call': np.int64(6),\n",
       " 'mobil': np.int64(49),\n",
       " 'co': np.int64(10),\n",
       " 'home': np.int64(31),\n",
       " 'want': np.int64(91),\n",
       " 'today': np.int64(84),\n",
       " 'cash': np.int64(8),\n",
       " 'day': np.int64(13),\n",
       " 'repli': np.int64(66),\n",
       " 'www': np.int64(97),\n",
       " 'right': np.int64(67),\n",
       " 'thank': np.int64(80),\n",
       " 'take': np.int64(77),\n",
       " 'time': np.int64(83),\n",
       " 'use': np.int64(89),\n",
       " 'messag': np.int64(46),\n",
       " 'oh': np.int64(57),\n",
       " 'ye': np.int64(98),\n",
       " 'make': np.int64(44),\n",
       " 'way': np.int64(93),\n",
       " 'feel': np.int64(17),\n",
       " 'dont': np.int64(15),\n",
       " 'miss': np.int64(48),\n",
       " 'ur': np.int64(88),\n",
       " 'tri': np.int64(86),\n",
       " 'da': np.int64(12),\n",
       " 'lor': np.int64(41),\n",
       " 'meet': np.int64(45),\n",
       " 'realli': np.int64(65),\n",
       " 'get': np.int64(21),\n",
       " 'know': np.int64(34),\n",
       " 'lol': np.int64(40),\n",
       " 'love': np.int64(42),\n",
       " 'let': np.int64(38),\n",
       " 'work': np.int64(96),\n",
       " 'wait': np.int64(90),\n",
       " 'sure': np.int64(76),\n",
       " 'yeah': np.int64(99),\n",
       " 'tell': np.int64(78),\n",
       " 'anyth': np.int64(2),\n",
       " 'pleas': np.int64(63),\n",
       " 'msg': np.int64(51),\n",
       " 'see': np.int64(70),\n",
       " 'pl': np.int64(62),\n",
       " 'need': np.int64(53),\n",
       " 'tomorrow': np.int64(85),\n",
       " 'hope': np.int64(32),\n",
       " 'well': np.int64(95),\n",
       " 'lt': np.int64(43),\n",
       " 'gt': np.int64(27),\n",
       " 'ask': np.int64(3),\n",
       " 'morn': np.int64(50),\n",
       " 'happi': np.int64(28),\n",
       " 'sorri': np.int64(73),\n",
       " 'give': np.int64(22),\n",
       " 'new': np.int64(54),\n",
       " 'find': np.int64(18),\n",
       " 'later': np.int64(36),\n",
       " 'pick': np.int64(61),\n",
       " 'good': np.int64(24),\n",
       " 'come': np.int64(11),\n",
       " 'said': np.int64(68),\n",
       " 'hi': np.int64(30),\n",
       " 'babe': np.int64(4),\n",
       " 'im': np.int64(33),\n",
       " 'much': np.int64(52),\n",
       " 'stop': np.int64(75),\n",
       " 'one': np.int64(59),\n",
       " 'night': np.int64(55),\n",
       " 'dear': np.int64(14),\n",
       " 'thing': np.int64(81),\n",
       " 'last': np.int64(35),\n",
       " 'min': np.int64(47),\n",
       " 'number': np.int64(56),\n",
       " 'leav': np.int64(37),\n",
       " 'also': np.int64(1),\n",
       " 'sleep': np.int64(72),\n",
       " 'care': np.int64(7),\n",
       " 'phone': np.int64(60)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_ #with the index of the words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d588fb7",
   "metadata": {},
   "source": [
    "N_Grams\n",
    "\n",
    "for refernce- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860033a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create bag of words model with ngram\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv2=CountVectorizer(max_features=100,binary=True,ngram_range=(3,3))#using trigram and trigram\n",
    "## here i am taking 100 that has maximum number of occurance\n",
    "#also enabled binary BOW\n",
    "x=cv2.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d076ae",
   "metadata": {},
   "source": [
    "Here used trigram grouped 3 words from the vocab and formed a new word for better processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcd44f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'call claim code': np.int64(8),\n",
       " 'like lt gt': np.int64(52),\n",
       " 'sorri call later': np.int64(77),\n",
       " 'pleas call custom': np.int64(64),\n",
       " 'call custom servic': np.int64(9),\n",
       " 'custom servic repres': np.int64(23),\n",
       " 'guarante cash prize': np.int64(42),\n",
       " 'draw show prize': np.int64(27),\n",
       " 'show prize guarante': np.int64(75),\n",
       " 'prize guarante call': np.int64(71),\n",
       " 'guarante call claim': np.int64(40),\n",
       " 'special select receiv': np.int64(79),\n",
       " 'speak live oper': np.int64(78),\n",
       " 'privat account statement': np.int64(69),\n",
       " 'account statement show': np.int64(0),\n",
       " 'call identifi code': np.int64(10),\n",
       " 'identifi code expir': np.int64(48),\n",
       " 'award bonu caller': np.int64(5),\n",
       " 'bonu caller prize': np.int64(6),\n",
       " 'select receiv award': np.int64(74),\n",
       " 'match pleas call': np.int64(58),\n",
       " 'urgent tri contact': np.int64(97),\n",
       " 'lt decim gt': np.int64(54),\n",
       " 'admir look make': np.int64(1),\n",
       " 'find reveal think': np.int64(34),\n",
       " 'think ur special': np.int64(86),\n",
       " 'ur special call': np.int64(93),\n",
       " 'draw txt music': np.int64(28),\n",
       " 'www ldew com': np.int64(98),\n",
       " 'anytim network min': np.int64(2),\n",
       " 'camcord repli call': np.int64(15),\n",
       " 'ur cash balanc': np.int64(91),\n",
       " 'cash balanc current': np.int64(17),\n",
       " 'pound maxim ur': np.int64(67),\n",
       " 'maxim ur cash': np.int64(59),\n",
       " 'ur cash send': np.int64(92),\n",
       " 'hg suit land': np.int64(45),\n",
       " 'suit land row': np.int64(82),\n",
       " 'land row hl': np.int64(51),\n",
       " 'doubl min txt': np.int64(26),\n",
       " 'call mobileupd call': np.int64(12),\n",
       " 'mobileupd call optout': np.int64(61),\n",
       " 'lt gt min': np.int64(56),\n",
       " 'thank rington order': np.int64(85),\n",
       " 'free entri weekli': np.int64(36),\n",
       " 'urgent mobil number': np.int64(95),\n",
       " 'mobil number award': np.int64(60),\n",
       " 'guarante call land': np.int64(41),\n",
       " 'call land line': np.int64(11),\n",
       " 'land line claim': np.int64(50),\n",
       " 'line claim valid': np.int64(53),\n",
       " 'claim valid hr': np.int64(19),\n",
       " 'lt gt lt': np.int64(55),\n",
       " 'gt lt gt': np.int64(39),\n",
       " 'tenerif holiday cash': np.int64(83),\n",
       " 'caller prize nd': np.int64(14),\n",
       " 'prize nd attempt': np.int64(72),\n",
       " 'nd attempt contact': np.int64(62),\n",
       " 'attempt contact call': np.int64(3),\n",
       " 'statement show un': np.int64(80),\n",
       " 'show un redeem': np.int64(76),\n",
       " 'un redeem point': np.int64(90),\n",
       " 'redeem point call': np.int64(73),\n",
       " 'point call identifi': np.int64(66),\n",
       " 'kiss across sea': np.int64(49),\n",
       " 'new video phone': np.int64(63),\n",
       " 'dear voucher holder': np.int64(25),\n",
       " 'happi new year': np.int64(44),\n",
       " 'everi wk txt': np.int64(31),\n",
       " 'lt gt minut': np.int64(57),\n",
       " 'free st week': np.int64(37),\n",
       " 'everi week txt': np.int64(30),\n",
       " 'getz co uk': np.int64(38),\n",
       " 'co uk pobox': np.int64(20),\n",
       " 'uk pobox wq': np.int64(89),\n",
       " 'holiday cash await': np.int64(46),\n",
       " 'cash await collect': np.int64(16),\n",
       " 'await collect sae': np.int64(4),\n",
       " 'collect sae cs': np.int64(21),\n",
       " 'half price line': np.int64(43),\n",
       " 'price line rental': np.int64(68),\n",
       " 'stop text call': np.int64(81),\n",
       " 'pleas call landlin': np.int64(65),\n",
       " 'tri contact today': np.int64(88),\n",
       " 'contact today draw': np.int64(22),\n",
       " 'today draw show': np.int64(87),\n",
       " 'final attempt contact': np.int64(32),\n",
       " 'day find log': np.int64(24),\n",
       " 'find log onto': np.int64(33),\n",
       " 'http www urawinn': np.int64(47),\n",
       " 'www urawinn com': np.int64(99),\n",
       " 'urawinn com fantast': np.int64(94),\n",
       " 'call per min': np.int64(13),\n",
       " 'bt nation rate': np.int64(7),\n",
       " 'prize claim easi': np.int64(70),\n",
       " 'claim easi call': np.int64(18),\n",
       " 'easi call per': np.int64(29),\n",
       " 'urgent pleas call': np.int64(96),\n",
       " 'text free camcord': np.int64(84),\n",
       " 'free camcord repli': np.int64(35)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2b2ef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 100\n",
      "Shape of feature matrix: (5169, 100)\n",
      "VOCABULARY ANALYSIS\n",
      "\n",
      "Vocabulary (sorted by feature index):\n",
      "account statement show(0)  admir look make(1)  anytim network min(2)  attempt contact call(3)  await collect sae(4)  \n",
      "award bonu caller(5)  bonu caller prize(6)  bt nation rate(7)  call claim code(8)  call custom servic(9)  \n",
      "call identifi code(10)  call land line(11)  call mobileupd call(12)  call per min(13)  caller prize nd(14)  \n",
      "camcord repli call(15)  cash await collect(16)  cash balanc current(17)  claim easi call(18)  claim valid hr(19)  \n",
      "co uk pobox(20)  collect sae cs(21)  contact today draw(22)  custom servic repres(23)  day find log(24)  \n",
      "dear voucher holder(25)  doubl min txt(26)  draw show prize(27)  draw txt music(28)  easi call per(29)  \n",
      "everi week txt(30)  everi wk txt(31)  final attempt contact(32)  find log onto(33)  find reveal think(34)  \n",
      "free camcord repli(35)  free entri weekli(36)  free st week(37)  getz co uk(38)  gt lt gt(39)  \n",
      "guarante call claim(40)  guarante call land(41)  guarante cash prize(42)  half price line(43)  happi new year(44)  \n",
      "hg suit land(45)  holiday cash await(46)  http www urawinn(47)  identifi code expir(48)  kiss across sea(49)  \n",
      "land line claim(50)  land row hl(51)  like lt gt(52)  line claim valid(53)  lt decim gt(54)  \n",
      "lt gt lt(55)  lt gt min(56)  lt gt minut(57)  match pleas call(58)  maxim ur cash(59)  \n",
      "mobil number award(60)  mobileupd call optout(61)  nd attempt contact(62)  new video phone(63)  pleas call custom(64)  \n",
      "pleas call landlin(65)  point call identifi(66)  pound maxim ur(67)  price line rental(68)  privat account statement(69)  \n",
      "prize claim easi(70)  prize guarante call(71)  prize nd attempt(72)  redeem point call(73)  select receiv award(74)  \n",
      "show prize guarante(75)  show un redeem(76)  sorri call later(77)  speak live oper(78)  special select receiv(79)  \n",
      "statement show un(80)  stop text call(81)  suit land row(82)  tenerif holiday cash(83)  text free camcord(84)  \n",
      "thank rington order(85)  think ur special(86)  today draw show(87)  tri contact today(88)  uk pobox wq(89)  \n",
      "un redeem point(90)  ur cash balanc(91)  ur cash send(92)  ur special call(93)  urawinn com fantast(94)  \n",
      "urgent mobil number(95)  urgent pleas call(96)  urgent tri contact(97)  www ldew com(98)  www urawinn com(99)  \n",
      "\n",
      "==================================================\n",
      "BIGRAMS IN VOCABULARY\n",
      "==================================================\n",
      "\n",
      "Number of unigrams: 0\n",
      "Number of bigrams: 100\n",
      "\n",
      "Bigrams found:\n",
      "  'account statement show' -> index 0\n",
      "  'admir look make' -> index 1\n",
      "  'anytim network min' -> index 2\n",
      "  'attempt contact call' -> index 3\n",
      "  'await collect sae' -> index 4\n",
      "  'award bonu caller' -> index 5\n",
      "  'bonu caller prize' -> index 6\n",
      "  'bt nation rate' -> index 7\n",
      "  'call claim code' -> index 8\n",
      "  'call custom servic' -> index 9\n",
      "  'call identifi code' -> index 10\n",
      "  'call land line' -> index 11\n",
      "  'call mobileupd call' -> index 12\n",
      "  'call per min' -> index 13\n",
      "  'caller prize nd' -> index 14\n",
      "  'camcord repli call' -> index 15\n",
      "  'cash await collect' -> index 16\n",
      "  'cash balanc current' -> index 17\n",
      "  'claim easi call' -> index 18\n",
      "  'claim valid hr' -> index 19\n",
      "  'co uk pobox' -> index 20\n",
      "  'collect sae cs' -> index 21\n",
      "  'contact today draw' -> index 22\n",
      "  'custom servic repres' -> index 23\n",
      "  'day find log' -> index 24\n",
      "  'dear voucher holder' -> index 25\n",
      "  'doubl min txt' -> index 26\n",
      "  'draw show prize' -> index 27\n",
      "  'draw txt music' -> index 28\n",
      "  'easi call per' -> index 29\n",
      "  'everi week txt' -> index 30\n",
      "  'everi wk txt' -> index 31\n",
      "  'final attempt contact' -> index 32\n",
      "  'find log onto' -> index 33\n",
      "  'find reveal think' -> index 34\n",
      "  'free camcord repli' -> index 35\n",
      "  'free entri weekli' -> index 36\n",
      "  'free st week' -> index 37\n",
      "  'getz co uk' -> index 38\n",
      "  'gt lt gt' -> index 39\n",
      "  'guarante call claim' -> index 40\n",
      "  'guarante call land' -> index 41\n",
      "  'guarante cash prize' -> index 42\n",
      "  'half price line' -> index 43\n",
      "  'happi new year' -> index 44\n",
      "  'hg suit land' -> index 45\n",
      "  'holiday cash await' -> index 46\n",
      "  'http www urawinn' -> index 47\n",
      "  'identifi code expir' -> index 48\n",
      "  'kiss across sea' -> index 49\n",
      "  'land line claim' -> index 50\n",
      "  'land row hl' -> index 51\n",
      "  'like lt gt' -> index 52\n",
      "  'line claim valid' -> index 53\n",
      "  'lt decim gt' -> index 54\n",
      "  'lt gt lt' -> index 55\n",
      "  'lt gt min' -> index 56\n",
      "  'lt gt minut' -> index 57\n",
      "  'match pleas call' -> index 58\n",
      "  'maxim ur cash' -> index 59\n",
      "  'mobil number award' -> index 60\n",
      "  'mobileupd call optout' -> index 61\n",
      "  'nd attempt contact' -> index 62\n",
      "  'new video phone' -> index 63\n",
      "  'pleas call custom' -> index 64\n",
      "  'pleas call landlin' -> index 65\n",
      "  'point call identifi' -> index 66\n",
      "  'pound maxim ur' -> index 67\n",
      "  'price line rental' -> index 68\n",
      "  'privat account statement' -> index 69\n",
      "  'prize claim easi' -> index 70\n",
      "  'prize guarante call' -> index 71\n",
      "  'prize nd attempt' -> index 72\n",
      "  'redeem point call' -> index 73\n",
      "  'select receiv award' -> index 74\n",
      "  'show prize guarante' -> index 75\n",
      "  'show un redeem' -> index 76\n",
      "  'sorri call later' -> index 77\n",
      "  'speak live oper' -> index 78\n",
      "  'special select receiv' -> index 79\n",
      "  'statement show un' -> index 80\n",
      "  'stop text call' -> index 81\n",
      "  'suit land row' -> index 82\n",
      "  'tenerif holiday cash' -> index 83\n",
      "  'text free camcord' -> index 84\n",
      "  'thank rington order' -> index 85\n",
      "  'think ur special' -> index 86\n",
      "  'today draw show' -> index 87\n",
      "  'tri contact today' -> index 88\n",
      "  'uk pobox wq' -> index 89\n",
      "  'un redeem point' -> index 90\n",
      "  'ur cash balanc' -> index 91\n",
      "  'ur cash send' -> index 92\n",
      "  'ur special call' -> index 93\n",
      "  'urawinn com fantast' -> index 94\n",
      "  'urgent mobil number' -> index 95\n",
      "  'urgent pleas call' -> index 96\n",
      "  'urgent tri contact' -> index 97\n",
      "  'www ldew com' -> index 98\n",
      "  'www urawinn com' -> index 99\n"
     ]
    }
   ],
   "source": [
    "# Let's analyze the vocabulary in more detail\n",
    "print(f\"Total vocabulary size: {len(cv2.vocabulary_)}\")\n",
    "print(f\"Shape of feature matrix: {x.shape}\")\n",
    "print(\"VOCABULARY ANALYSIS\")\n",
    "\n",
    "# Sort vocabulary by index to see the order\n",
    "vocab_sorted = sorted(cv2.vocabulary_.items(), key=lambda x: x[1])\n",
    "\n",
    "print(\"\\nVocabulary (sorted by feature index):\")\n",
    "for i, (word, index) in enumerate(vocab_sorted):\n",
    "    if i % 5 == 0 and i > 0:  # Print 5 words per line\n",
    "        print()\n",
    "    print(f\"{word}({index})\", end=\"  \")\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"BIGRAMS IN VOCABULARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Identify bigrams (words with spaces)\n",
    "bigrams = [word for word in cv2.vocabulary_.keys() if ' ' in word]\n",
    "unigrams = [word for word in cv2.vocabulary_.keys() if ' ' not in word]\n",
    "\n",
    "print(f\"\\nNumber of unigrams: {len(unigrams)}\")\n",
    "print(f\"Number of bigrams: {len(bigrams)}\")\n",
    "\n",
    "if bigrams:\n",
    "    print(\"\\nBigrams found:\")\n",
    "    for bigram in sorted(bigrams):\n",
    "        print(f\"  '{bigram}' -> index {cv2.vocabulary_[bigram]}\")\n",
    "else:\n",
    "    print(\"\\nNo bigrams found in top 100 features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c4d505f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], shape=(5169, 100))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
