# ğŸ¤– GenAI Learning Repository

A comprehensive learning journey through Generative AI, covering Python fundamentals, Natural Language Processing, Deep Learning, and hands-on mini projects using LangChain and HuggingFace.

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange.svg)](https://www.tensorflow.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.52-red.svg)](https://streamlit.io/)

---

## ğŸ“š Table of Contents

- [Learning Path](#-learning-path)
  - [Python & OOP](#-python--oop)
  - [NLP Fundamentals](#-nlp-fundamentals)
  - [Deep Learning](#-deep-learning)
- [Mini Projects](#-mini-projects)
- [Tech Stack](#-tech-stack)
- [Getting Started](#-getting-started)

---

## ğŸ¯ Learning Path

### ğŸ Python & OOP

ğŸ“‚ [View Notebooks](./Hands-On-Notebooks/1.OOPS) | ğŸ“‚ [Streamlit Projects](./Hands-On-Notebooks/2.STREAMLIT)

#### **Object-Oriented Programming**

<details>
<summary><b>Core OOP Concepts</b></summary>

- **OOP Basics**: Classes, objects, attributes, methods, constructors
- **Inheritance**: Parent/child classes, method overriding, super keyword
- **Polymorphism**: Method overloading, method overriding, Abstract Base Class
- **Encapsulation**: Private/protected variables, getters & setters
- **Abstraction**: Abstract classes, abstract methods, ABC module
- **Magic Methods**: `__init__`, `__str__`, `__repr__`, `__len__`, `__getitem__`
- **Operator Overloading**: Arithmetic & comparison operators

</details>

#### **Streamlit Framework**

- Building interactive web applications
- Widgets and user inputs
- Data visualization
- ML/AI app interfaces

---

### ğŸ“ NLP Fundamentals

ğŸ“‚ [View Notebooks](./Hands-On-Notebooks/3.NLP(Word%20Embedding))

#### **Text Preprocessing**

| Topic | Concepts Covered |
|-------|-----------------|
| **Tokenization** | Word, sentence, and subword tokenization |
| **Stemming** | Porter, Regexp, Snowball stemmers |
| **Lemmatization** | WordNet Lemmatizer, comparison with stemming |
| **Stopwords** | Removal techniques and applications |
| **POS Tagging** | Part-of-speech tagging with NLTK |
| **NER** | Named Entity Recognition, chunking, tree structures |

#### **Word Embedding Techniques**

| Technique | Description |
|-----------|-------------|
| **One Hot Encoding** | Binary vector representation |
| **Bag of Words** | Document-term frequency matrix |
| **N-Grams** | Bigrams, trigrams for context |
| **TF-IDF** | Term frequency-inverse document frequency |
| **Word2Vec** | Dense word embeddings, CBOW, Skip-gram |

---

### ğŸ§  Deep Learning

ğŸ“‚ [View Notebooks](./Hands-On-Notebooks/4.DEEP-LEARNING)

#### **Recurrent Neural Networks (RNN)**

<details>
<summary><b>Simple RNN</b></summary>

- **ANN vs RNN**: Understanding sequential data challenges
- **Simple RNN**: Architecture, forward/backward propagation
- **Vanishing Gradient Problem**: Challenges with long sequences and why it matters

</details>

#### **Long Short-Term Memory (LSTM)**

<details>
<summary><b>LSTM Architecture & Components</b></summary>

ğŸ“‚ [LSTM Learning Materials](./Hands-On-Notebooks/4.DEEP-LEARNING/LSTM-RNN) | ğŸ–¼ï¸ [Reference Images](./Hands-On-Notebooks/4.DEEP-LEARNING/LSTM-RNN/images)

**Why LSTM?**
- Solves the vanishing gradient problem of simple RNNs
- Enables learning from long-term dependencies
- Maintains information across long sequences

**Core Components:**

| Component | Description |
|-----------|-------------|
| **Cell State (Ct)** | The "memory" of the network, carries information across time steps |
| **Hidden State (ht)** | The output of the LSTM cell at each time step |
| **Forget Gate** | Decides what information to discard from the cell state |
| **Input Gate** | Decides what new information to store in the cell state |
| **Output Gate** | Decides what information from the cell state to output |

**Gate Operations:**

1. **Forget Gate (ft)**: `ft = Ïƒ(Wf Â· [ht-1, xt] + bf)`
   - Uses sigmoid activation to output values between 0 and 1
   - 0 = completely forget, 1 = completely keep

2. **Input Gate (it)**: `it = Ïƒ(Wi Â· [ht-1, xt] + bi)`
   - Decides which values to update in the cell state
   - Works with candidate values: `CÌƒt = tanh(Wc Â· [ht-1, xt] + bc)`

3. **Cell State Update**: `Ct = ft * Ct-1 + it * CÌƒt`
   - Combines forget and input operations
   - Maintains long-term memory

4. **Output Gate (ot)**: `ot = Ïƒ(Wo Â· [ht-1, xt] + bo)`
   - Decides what to output based on cell state
   - Final output: `ht = ot * tanh(Ct)`

**Key Advantages:**
- Better gradient flow during backpropagation
- Selective memory (can choose what to remember/forget)
- Handles long-term dependencies effectively
- Widely used in NLP, time series, and sequence modeling

</details>

---

## ğŸš€ Mini Projects

ğŸ“‚ [View All Projects](./Mini-projects)

### 1ï¸âƒ£ Customer Churn Prediction ğŸ“Š

> **Binary Classification** using Artificial Neural Networks

**ğŸ¯ Objective:** Predict whether a customer will leave the bank based on their profile and behavior.

**âœ¨ Features:**
- ğŸ–¥ï¸ Interactive Streamlit web interface
- ğŸ§  Deep Learning (ANN) for binary classification
- ğŸ“ˆ Real-time prediction with probability scores
- ğŸ“Š Customer demographics, credit score, balance, products

**ğŸ”§ Tech Stack:**
- TensorFlow/Keras
- Streamlit
- scikit-learn (StandardScaler, LabelEncoder, OneHotEncoder)

**ğŸ“ Project Structure:**
```
CHURN-MODELLING/
â”œâ”€â”€ app.py                    # Streamlit application
â”œâ”€â”€ experiments.ipynb         # Model training & experimentation
â”œâ”€â”€ prediction.ipynb          # Model evaluation
â”œâ”€â”€ model.h5                  # Trained model
â””â”€â”€ *.pkl                     # Preprocessing artifacts
```

---

### 2ï¸âƒ£ Salary Regression Predictor ğŸ’°

> **Regression Model** to estimate customer salary

**ğŸ¯ Objective:** Predict estimated annual salary based on customer banking profile.

**âœ¨ Features:**
- ğŸ–¥ï¸ Beautiful Streamlit UI with metric displays
- ğŸ§  ANN Regression model
- ğŸ“Š Customer profile summary visualization
- ğŸ“ˆ TensorBoard integration for training monitoring

**ğŸ”§ Tech Stack:**
- TensorFlow/Keras
- Streamlit
- TensorBoard
- scikit-learn (StandardScaler, LabelEncoder, OneHotEncoder)

**ğŸ“ Project Structure:**
```
Regression/
â”œâ”€â”€ streamlit_reg.py          # Streamlit application
â”œâ”€â”€ Salaryregression.ipynb    # Model training notebook
â”œâ”€â”€ regression_model.h5       # Trained regression model
â”œâ”€â”€ logs/                     # TensorBoard logs
â””â”€â”€ *.pkl                     # Preprocessing artifacts
```

---

### 3ï¸âƒ£ Movie Review Sentiment Analysis ğŸ¬

> **RNN-based Sentiment Classification** for IMDB movie reviews

**ğŸ¯ Objective:** Classify movie reviews as positive or negative using Recurrent Neural Networks.

**âœ¨ Features:**
- ğŸ–¥ï¸ Clean and intuitive Streamlit interface
- ğŸ§  Simple RNN model trained on IMDB dataset
- ğŸ“Š Real-time sentiment prediction with confidence scores
- ğŸ­ Handles user-provided movie reviews of any length
- ğŸ“ˆ Preprocessing pipeline with word embedding

**ğŸ”§ Tech Stack:**
- TensorFlow/Keras (SimpleRNN)
- Streamlit
- IMDB Dataset (10,000 vocabulary size)
- Sequence padding (max length: 500)

**ğŸ“ Project Structure:**
```
Movie-Review-RNN/
â”œâ”€â”€ main.py                   # Streamlit application
â”œâ”€â”€ RnnProject.ipynb          # Model training notebook
â”œâ”€â”€ prediction.ipynb          # Model evaluation & testing
â””â”€â”€ simple_rnn_imdb.keras     # Trained RNN model
```

---

## ğŸ› ï¸ Tech Stack

### **Core Technologies**

| Category | Tools & Libraries |
|----------|------------------|
| **Languages** | Python 3.10+ |
| **Deep Learning** | TensorFlow 2.15, Keras |
| **ML Libraries** | scikit-learn, NumPy, Pandas |
| **NLP** | NLTK, Gensim |
| **Web Framework** | Streamlit 1.52 |
| **Visualization** | Matplotlib, Seaborn, TensorBoard |
| **Version Control** | Git, GitHub |

---

## ğŸš¦ Getting Started

### Prerequisites

```bash
Python 3.10 or higher
pip (Python package manager)
```

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/sukrit-89/genai-playground-langchain-hf.git
   cd genai-playground-langchain-hf
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

### Running Mini Projects

#### Churn Prediction App
```bash
cd Mini-projects/CHURN-MODELLING
streamlit run app.py
```

#### Salary Regression App
```bash
cd Mini-projects/Regression
streamlit run streamlit_reg.py
```

#### Movie Review Sentiment Analysis
```bash
cd Mini-projects/RNN/Movie-Review-RNN
streamlit run main.py
```

---

## ğŸ“ˆ Learning Progress

- âœ… Python OOP Fundamentals
- âœ… Streamlit Framework
- âœ… NLP Text Preprocessing
- âœ… Word Embedding Techniques
- âœ… Deep Learning Basics (ANN, RNN)
- âœ… LSTM-RNN Architecture
- âœ… Binary Classification Project (Churn Prediction)
- âœ… Regression Project (Salary Estimation)
- âœ… RNN Sentiment Analysis Project (Movie Reviews)
- ğŸ”„ Advanced Deep Learning (GRU, Bidirectional RNNs, Transformers) - In Progress

---

## ğŸ“ Notes

- All notebooks are organized by topic and concept
- Model files (`.h5`, `.pkl`) are excluded from version control
- TensorBoard logs available for training visualization
- Datasets are not tracked in Git (see `.gitignore`)

---

## ğŸ¤ Contributing

This is a personal learning repository. However, suggestions and feedback are always welcome!

---

## ğŸ“„ License

This project is for educational purposes.

---

<div align="center">

**Happy Learning! ğŸš€**

Made with â¤ï¸ by Sukrit

</div>
